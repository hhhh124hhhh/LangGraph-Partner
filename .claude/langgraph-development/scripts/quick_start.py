#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LangGraphä¸€é”®å¿«é€Ÿå¯åŠ¨å·¥å…·

ä¸“ä¸ºåˆå­¦è€…è®¾è®¡çš„é›¶é…ç½®å¯åŠ¨è„šæœ¬ï¼Œè‡ªåŠ¨æ£€æµ‹ç¯å¢ƒã€å®‰è£…ä¾èµ–ã€
å¯åŠ¨ç¤ºä¾‹ï¼Œè®©ç”¨æˆ·åœ¨5åˆ†é’Ÿå†…ä½“éªŒLangGraphçš„å¼ºå¤§åŠŸèƒ½ã€‚
"""

import os
import sys
import json
import subprocess
import time
import webbrowser
from pathlib import Path
from typing import Dict, List, Any, Optional
import argparse

class QuickStart:
    """LangGraphå¿«é€Ÿå¯åŠ¨å™¨"""

    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.requirements = [
            "langgraph>=0.2.16",
            "langchain>=0.3.0",
            "langchain-openai>=0.2.0",
            "langchain-anthropic>=0.2.0",
            "langchain-community>=0.3.0",
            "python-dotenv>=1.0.0",
            "rich>=13.0.0",
            "jupyter>=1.1.0",
            "notebook>=7.0.0"
        ]
        self.min_python_version = (3, 9)

    def print_banner(self):
        """æ‰“å°æ¬¢è¿æ¨ªå¹…"""
        banner = """
ğŸš€ LangGraph å¿«é€Ÿå¯åŠ¨å·¥å…· v1.0

âœ¨ è®©ä½ åœ¨5åˆ†é’Ÿå†…ä½“éªŒLangGraphçš„å¼ºå¤§åŠŸèƒ½
ğŸ¯ ä¸“ä¸ºåˆå­¦è€…è®¾è®¡ï¼Œé›¶é…ç½®å¯åŠ¨
ğŸ“š åŒ…å«å®Œæ•´ç¤ºä¾‹å’Œäº¤äº’å¼æ•™ç¨‹

        """
        print(banner)

    def check_python_version(self) -> bool:
        """æ£€æŸ¥Pythonç‰ˆæœ¬"""
        version = sys.version_info
        if version >= self.min_python_version:
            print(f"âœ… Pythonç‰ˆæœ¬æ£€æŸ¥é€šè¿‡: {version.major}.{version.minor}.{version.micro}")
            return True
        else:
            print(f"âŒ Pythonç‰ˆæœ¬è¿‡ä½: {version.major}.{version.minor}.{version.micro}")
            print(f"   éœ€è¦Python {'.'.join(map(str, self.min_python_version))} æˆ–æ›´é«˜ç‰ˆæœ¬")
            return False

    def check_dependencies(self) -> List[str]:
        """æ£€æŸ¥å·²å®‰è£…çš„ä¾èµ–"""
        missing = []
        for package in self.requirements:
            package_name = package.split('>=')[0].split('==')[0]
            try:
                __import__(package_name.replace('-', '_'))
                print(f"âœ… {package_name} å·²å®‰è£…")
            except ImportError:
                print(f"âŒ {package_name} æœªå®‰è£…")
                missing.append(package)
        return missing

    def install_dependencies(self, missing_packages: List[str]) -> bool:
        """å®‰è£…ç¼ºå¤±çš„ä¾èµ–"""
        if not missing_packages:
            return True

        print(f"\nğŸ“¦ æ­£åœ¨å®‰è£… {len(missing_packages)} ä¸ªä¾èµ–åŒ…...")
        print("   è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")

        try:
            # å‡çº§pip
            subprocess.run([sys.executable, "-m", "pip", "install", "--upgrade", "pip"],
                         check=True, capture_output=True)

            # å®‰è£…ä¾èµ–
            cmd = [sys.executable, "-m", "pip", "install"] + missing_packages
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)

            print("âœ… ä¾èµ–å®‰è£…å®Œæˆ!")
            return True

        except subprocess.CalledProcessError as e:
            print(f"âŒ ä¾èµ–å®‰è£…å¤±è´¥: {e}")
            print(f"   é”™è¯¯ä¿¡æ¯: {e.stderr}")
            return False

    def create_env_file(self) -> bool:
        """åˆ›å»ºç¯å¢ƒé…ç½®æ–‡ä»¶"""
        env_file = self.project_root / ".env"
        env_example = self.project_root / ".env.example"

        if env_file.exists():
            print("âœ… ç¯å¢ƒé…ç½®æ–‡ä»¶å·²å­˜åœ¨")
            return True

        print("ğŸ“ åˆ›å»ºç¯å¢ƒé…ç½®æ–‡ä»¶...")

        env_content = """# LangGraph ç¯å¢ƒé…ç½®
# å¤åˆ¶æ­¤æ–‡ä»¶ä¸º .env å¹¶å¡«å…¥ä½ çš„APIå¯†é’¥

# OpenAI APIå¯†é’¥ (å¿…éœ€)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic APIå¯†é’¥ (å¯é€‰)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# LangSmithè¿½è¸ª (å¯é€‰ï¼Œæ¨èç”¨äºå­¦ä¹ )
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=langgraph-quickstart

# å…¶ä»–é…ç½®
LANGCHAIN_VERBOSE=false
"""

        try:
            with open(env_file, 'w', encoding='utf-8') as f:
                f.write(env_content)
            print("âœ… ç¯å¢ƒé…ç½®æ–‡ä»¶åˆ›å»ºæˆåŠŸ!")
            print(f"   æ–‡ä»¶ä½ç½®: {env_file}")
            print("   è¯·ç¼–è¾‘æ–‡ä»¶å¹¶æ·»åŠ ä½ çš„APIå¯†é’¥")
            return True
        except Exception as e:
            print(f"âŒ ç¯å¢ƒé…ç½®æ–‡ä»¶åˆ›å»ºå¤±è´¥: {e}")
            return False

    def setup_project_structure(self) -> bool:
        """è®¾ç½®é¡¹ç›®ç»“æ„"""
        print("ğŸ“ è®¾ç½®é¡¹ç›®ç»“æ„...")

        directories = [
            "examples",
            "notebooks",
            "data",
            "logs",
            "outputs"
        ]

        for dir_name in directories:
            dir_path = self.project_root / dir_name
            dir_path.mkdir(exist_ok=True)
            print(f"âœ… åˆ›å»ºç›®å½•: {dir_name}")

        return True

    def run_basic_test(self) -> bool:
        """è¿è¡ŒåŸºç¡€æµ‹è¯•"""
        print("ğŸ§ª è¿è¡ŒåŸºç¡€åŠŸèƒ½æµ‹è¯•...")

        test_script = '''
import asyncio
from langchain_core.messages import HumanMessage
from langgraph.graph import StateGraph
from typing import TypedDict

class State(TypedDict):
    messages: list[str]

def chatbot(state: State):
    return {"messages": [f"æ”¶åˆ°æ¶ˆæ¯: {state['messages'][0]}"]}

async def test():
    try:
        graph = StateGraph(State)
        graph.add_node("chatbot", chatbot)
        graph.set_entry_point("chatbot")
        graph.set_finish_point("chatbot")

        compiled_graph = graph.compile()

        result = await compiled_graph.ainvoke({
            "messages": ["Hello LangGraph!"]
        })

        print("âœ… åŸºç¡€åŠŸèƒ½æµ‹è¯•é€šè¿‡!")
        return True
    except Exception as e:
        print(f"âŒ åŸºç¡€åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    asyncio.run(test())
'''

        try:
            test_file = self.project_root / "test_basic.py"
            with open(test_file, 'w', encoding='utf-8') as f:
                f.write(test_script)

            result = subprocess.run([sys.executable, str(test_file)],
                                  capture_output=True, text=True, timeout=30)

            if result.returncode == 0:
                print("âœ… " + result.stdout.split('\n')[0])
                test_file.unlink()  # åˆ é™¤æµ‹è¯•æ–‡ä»¶
                return True
            else:
                print(f"âŒ æµ‹è¯•å¤±è´¥: {result.stderr}")
                return False

        except subprocess.TimeoutExpired:
            print("âŒ æµ‹è¯•è¶…æ—¶")
            return False
        except Exception as e:
            print(f"âŒ æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")
            return False

    def create_examples(self) -> bool:
        """åˆ›å»ºç¤ºä¾‹æ–‡ä»¶"""
        print("ğŸ“š åˆ›å»ºå­¦ä¹ ç¤ºä¾‹...")

        examples = {
            "hello_world.py": self._get_hello_world_example(),
            "simple_chatbot.py": self._get_simple_chatbot_example(),
            "conditional_flow.py": self._get_conditional_flow_example()
        }

        examples_dir = self.project_root / "examples"

        for filename, content in examples.items():
            file_path = examples_dir / filename
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"âœ… åˆ›å»ºç¤ºä¾‹: {filename}")
            except Exception as e:
                print(f"âŒ åˆ›å»ºç¤ºä¾‹å¤±è´¥ {filename}: {e}")
                return False

        return True

    def _get_hello_world_example(self) -> str:
        """Hello Worldç¤ºä¾‹"""
        return '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LangGraph Hello World ç¤ºä¾‹

è¿™æ˜¯æœ€ç®€å•çš„LangGraphç¤ºä¾‹ï¼Œå¸®åŠ©ä½ ç†è§£åŸºæœ¬æ¦‚å¿µ
"""

from langchain_core.messages import HumanMessage, AIMessage
from langgraph.graph import StateGraph, MessageGraph
from typing import TypedDict, Annotated
import operator

# æ–¹æ³•1: ä½¿ç”¨StateGraph (æ¨è)
class State(TypedDict):
    messages: Annotated[list, operator.add]

def chatbot(state: State):
    """ç®€å•çš„èŠå¤©æœºå™¨äººå‡½æ•°"""
    messages = state["messages"]
    last_message = messages[-1].content if messages else ""

    # ç®€å•çš„å›å¤é€»è¾‘
    if "ä½ å¥½" in last_message:
        response = "ä½ å¥½ï¼æˆ‘æ˜¯LangGraphåŠ©æ‰‹ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼"
    elif "åŠŸèƒ½" in last_message:
        response = "LangGraphæ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ¡†æ¶ï¼Œå¯ä»¥æ„å»ºå¤æ‚çš„å¤šæ­¥éª¤AIåº”ç”¨ã€‚"
    else:
        response = f"æˆ‘æ”¶åˆ°ä½ çš„æ¶ˆæ¯: {last_message}"

    return {"messages": [AIMessage(content=response)]}

def create_state_graph():
    """åˆ›å»ºåŸºäºStateGraphçš„å·¥ä½œæµ"""
    graph = StateGraph(State)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("chatbot", chatbot)

    # è®¾ç½®å…¥å£å’Œå‡ºå£
    graph.set_entry_point("chatbot")
    graph.set_finish_point("chatbot")

    return graph.compile()

# æ–¹æ³•2: ä½¿ç”¨MessageGraph (æ›´ç®€å•)
def message_handler(messages):
    """æ¶ˆæ¯å¤„ç†å™¨"""
    last_message = messages[-1].content if messages else ""

    if "ä½ å¥½" in last_message:
        return AIMessage(content="ä½ å¥½ï¼å¾ˆé«˜å…´è§åˆ°ä½ ï¼")
    else:
        return AIMessage(content=f"ä½ è¯´: {last_message}")

def create_message_graph():
    """åˆ›å»ºåŸºäºMessageGraphçš„å·¥ä½œæµ"""
    graph = MessageGraph()

    graph.add_node("handler", message_handler)
    graph.set_entry_point("handler")
    graph.set_finish_point("handler")

    return graph.compile()

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ LangGraph Hello World ç¤ºä¾‹")
    print("=" * 50)

    # åˆ›å»ºå¹¶è¿è¡ŒStateGraphç¤ºä¾‹
    print("ğŸ“ StateGraph ç¤ºä¾‹:")
    state_graph = create_state_graph()

    result1 = await state_graph.ainvoke({
        "messages": [HumanMessage(content="ä½ å¥½")]
    })
    print(f"è¾“å…¥: ä½ å¥½")
    print(f"è¾“å‡º: {result1['messages'][-1].content}")
    print()

    result2 = await state_graph.ainvoke({
        "messages": [HumanMessage(content="LangGraphæœ‰ä»€ä¹ˆåŠŸèƒ½?")]
    })
    print(f"è¾“å…¥: LangGraphæœ‰ä»€ä¹ˆåŠŸèƒ½?")
    print(f"è¾“å‡º: {result2['messages'][-1].content}")
    print()

    # åˆ›å»ºå¹¶è¿è¡ŒMessageGraphç¤ºä¾‹
    print("ğŸ“ MessageGraph ç¤ºä¾‹:")
    message_graph = create_message_graph()

    result3 = await message_graph.ainvoke([
        HumanMessage(content="æµ‹è¯•æ¶ˆæ¯")
    ])
    print(f"è¾“å…¥: æµ‹è¯•æ¶ˆæ¯")
    print(f"è¾“å‡º: {result3[-1].content}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
'''

    def _get_simple_chatbot_example(self) -> str:
        """ç®€å•èŠå¤©æœºå™¨äººç¤ºä¾‹"""
        return '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LangGraphç®€å•èŠå¤©æœºå™¨äººç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•åˆ›å»ºä¸€ä¸ªæœ‰çŠ¶æ€çš„å¯¹è¯ç³»ç»Ÿ
"""

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph
from langgraph.checkpoint.memory import MemorySaver
from typing import TypedDict, Annotated
import operator

class State(TypedDict):
    messages: Annotated[list, operator.add]
    user_name: str

def chatbot_with_memory(state: State):
    """æœ‰è®°å¿†çš„èŠå¤©æœºå™¨äºº"""
    messages = state["messages"]
    user_name = state.get("user_name", "ç”¨æˆ·")

    # è·å–æœ€åä¸€æ¡äººç±»æ¶ˆæ¯
    human_messages = [msg for msg in messages if isinstance(msg, HumanMessage)]
    if not human_messages:
        return {"messages": [AIMessage(content="ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„AIåŠ©æ‰‹ã€‚")] }

    last_message = human_messages[-1].content

    # ç®€å•çš„å¯¹è¯é€»è¾‘
    if "æˆ‘å«" in last_message:
        # æå–ç”¨æˆ·å
        name = last_message.replace("æˆ‘å«", "").strip()
        return {
            "messages": [AIMessage(content=f"å¾ˆé«˜å…´è®¤è¯†ä½ ï¼Œ{name}ï¼")],
            "user_name": name
        }
    elif user_name != "ç”¨æˆ·" and "åå­—" in last_message:
        return {
            "messages": [AIMessage(content=f"æˆ‘è®°å¾—ä½ å«{user_name}ï¼")]
        }
    elif "å¤©æ°”" in last_message:
        return {
            "messages": [AIMessage(content="ä»Šå¤©å¤©æ°”æ™´æœ—ï¼Œé€‚åˆå­¦ä¹ ç¼–ç¨‹ï¼")]
        }
    else:
        return {
            "messages": [AIMessage(content=f"{user_name}ï¼Œä½ è¯´: {last_message}")]
        }

def create_chatbot():
    """åˆ›å»ºèŠå¤©æœºå™¨äºº"""
    graph = StateGraph(State)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("chatbot", chatbot_with_memory)

    # è®¾ç½®å…¥å£å’Œå‡ºå£
    graph.set_entry_point("chatbot")
    graph.set_finish_point("chatbot")

    # æ·»åŠ å†…å­˜æ£€æŸ¥ç‚¹ï¼Œç”¨äºä¿å­˜å¯¹è¯å†å²
    memory = MemorySaver()

    return graph.compile(checkpointer=memory)

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– LangGraph è®°å¿†èŠå¤©æœºå™¨äºº")
    print("=" * 50)
    print("è¾“å…¥æ¶ˆæ¯è¿›è¡Œå¯¹è¯ï¼Œè¾“å…¥ 'quit' é€€å‡º")
    print()

    chatbot = create_chatbot()

    # åˆå§‹åŒ–å¯¹è¯
    config = {"configurable": {"thread_id": "conversation-1"}}

    while True:
        try:
            user_input = input("ä½ : ").strip()

            if user_input.lower() in ['quit', 'é€€å‡º', 'q']:
                print("ğŸ‘‹ å†è§ï¼")
                break

            if not user_input:
                continue

            # å‘é€æ¶ˆæ¯ç»™èŠå¤©æœºå™¨äºº
            response = await chatbot.ainvoke(
                {"messages": [HumanMessage(content=user_input)]},
                config=config
            )

            # è·å–AIå›å¤
            ai_message = response["messages"][-1]
            print(f"æœºå™¨äºº: {ai_message.content}")

        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
'''

    def _get_conditional_flow_example(self) -> str:
        """æ¡ä»¶æµç¨‹ç¤ºä¾‹"""
        return '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LangGraphæ¡ä»¶æµç¨‹ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•æ ¹æ®æ¡ä»¶åŠ¨æ€æ§åˆ¶å·¥ä½œæµè·¯å¾„
"""

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph
from typing import TypedDict, Annotated, Literal
import operator
import re

class State(TypedDict):
    messages: Annotated[list, operator.add]
    query_type: str
    confidence: float

def classify_query(state: State):
    """æŸ¥è¯¢åˆ†ç±»å™¨"""
    messages = state["messages"]
    last_message = messages[-1].content.lower() if messages else ""

    # ç®€å•çš„å…³é”®è¯åˆ†ç±»
    if any(word in last_message for word in ["è®¡ç®—", "ç®—", "æ•°å­¦", "+", "-", "*", "/"]):
        query_type = "calculation"
    elif any(word in last_message for word in ["ç¿»è¯‘", "translate", "è‹±è¯­", "è‹±æ–‡"]):
        query_type = "translation"
    elif any(word in last_message for word in ["å¤©æ°”", "æ°”æ¸©", "ä¸‹é›¨"]):
        query_type = "weather"
    else:
        query_type = "general"

    return {"query_type": query_type, "confidence": 0.8}

def calculation_handler(state: State):
    """è®¡ç®—å¤„ç†å™¨"""
    messages = state["messages"]
    last_message = messages[-1].content if messages else ""

    # ç®€å•çš„æ•°å­¦è®¡ç®—
    try:
        # æå–æ•°å­—å’Œè¿ç®—ç¬¦
        expression = re.findall(r'[\d+\-*/().\s]+', last_message)
        if expression:
            result = eval(expression[0])
            response = f"è®¡ç®—ç»“æœ: {result}"
        else:
            response = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è¯†åˆ«è¿™ä¸ªæ•°å­¦è¡¨è¾¾å¼"
    except:
        response = "æŠ±æ­‰ï¼Œè®¡ç®—æ—¶å‡ºç°é”™è¯¯"

    return {"messages": [AIMessage(content=response)]}

def translation_handler(state: State):
    """ç¿»è¯‘å¤„ç†å™¨"""
    messages = state["messages"]
    last_message = messages[-1].content if messages else ""

    # æ¨¡æ‹Ÿç¿»è¯‘ï¼ˆå®é™…åº”ç”¨ä¸­ä¼šè°ƒç”¨ç¿»è¯‘APIï¼‰
    response = f"ç¿»è¯‘åŠŸèƒ½: '{last_message}' -> 'Translation: {last_message}'"

    return {"messages": [AIMessage(content=response)]}

def weather_handler(state: State):
    """å¤©æ°”å¤„ç†å™¨"""
    response = "ä»Šå¤©åŒ—äº¬å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©25Â°Cï¼Œé€‚åˆå¤–å‡ºæ´»åŠ¨ï¼"

    return {"messages": [AIMessage(content=response)]}

def general_handler(state: State):
    """é€šç”¨å¤„ç†å™¨"""
    messages = state["messages"]
    last_message = messages[-1].content if messages else ""

    response = f"æˆ‘æ”¶åˆ°äº†ä½ çš„æ¶ˆæ¯: {last_message}"

    return {"messages": [AIMessage(content=response)]}

def route_query(state: State) -> Literal["calculation", "translation", "weather", "general"]:
    """è·¯ç”±å‡½æ•° - æ ¹æ®æŸ¥è¯¢ç±»å‹å†³å®šä¸‹ä¸€æ­¥"""
    query_type = state.get("query_type", "general")

    if query_type == "calculation":
        return "calculation"
    elif query_type == "translation":
        return "translation"
    elif query_type == "weather":
        return "weather"
    else:
        return "general"

def create_conditional_graph():
    """åˆ›å»ºæ¡ä»¶è·¯ç”±å›¾"""
    graph = StateGraph(State)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("classify", classify_query)
    graph.add_node("calculation", calculation_handler)
    graph.add_node("translation", translation_handler)
    graph.add_node("weather", weather_handler)
    graph.add_node("general", general_handler)

    # è®¾ç½®å…¥å£
    graph.set_entry_point("classify")

    # æ·»åŠ æ¡ä»¶è·¯ç”±
    graph.add_conditional_edges(
        "classify",
        route_query,
        {
            "calculation": "calculation",
            "translation": "translation",
            "weather": "weather",
            "general": "general"
        }
    )

    # è®¾ç½®å‡ºå£
    graph.set_finish_point("calculation")
    graph.set_finish_point("translation")
    graph.set_finish_point("weather")
    graph.set_finish_point("general")

    return graph.compile()

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”€ LangGraph æ¡ä»¶æµç¨‹ç¤ºä¾‹")
    print("=" * 50)
    print("æ”¯æŒçš„åŠŸèƒ½:")
    print("- æ•°å­¦è®¡ç®— (å¦‚: è®¡ç®— 2+3)")
    print("- ç¿»è¯‘ (å¦‚: ç¿»è¯‘ hello)")
    print("- å¤©æ°”æŸ¥è¯¢ (å¦‚: ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·)")
    print("- é€šç”¨å¯¹è¯")
    print("è¾“å…¥ 'quit' é€€å‡º")
    print()

    graph = create_conditional_graph()

    test_queries = [
        "è®¡ç®— 123 + 456",
        "ç¿»è¯‘ hello world",
        "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·",
        "ä½ å¥½ï¼Œæˆ‘æ˜¯æ–°ç”¨æˆ·"
    ]

    print("ğŸ§ª è¿è¡Œæµ‹è¯•ç¤ºä¾‹:")
    print("-" * 30)

    for query in test_queries:
        print(f"\nè¾“å…¥: {query}")
        print(f"è·¯ç”±: ", end="")

        # è¿è¡Œåˆ†ç±»å™¨æŸ¥çœ‹è·¯ç”±
        classify_result = await graph.ainvoke({"messages": [HumanMessage(content=query)]})
        query_type = classify_result.get("query_type", "general")
        print(query_type)

        # è·å–æœ€ç»ˆå›å¤
        final_response = classify_result["messages"][-1].content
        print(f"è¾“å‡º: {final_response}")

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
'''

    def start_interactive_mode(self):
        """å¯åŠ¨äº¤äº’æ¨¡å¼"""
        print("\nğŸ‰ æ¬¢è¿ä½¿ç”¨LangGraphï¼")
        print("\nğŸ“š æ¨èçš„å­¦ä¹ è·¯å¾„:")
        print("1. æŸ¥çœ‹ examples/hello_world.py - ç†è§£åŸºæœ¬æ¦‚å¿µ")
        print("2. è¿è¡Œ examples/simple_chatbot.py - ä½“éªŒæœ‰çŠ¶æ€å¯¹è¯")
        print("3. å­¦ä¹  examples/conditional_flow.py - æŒæ¡æ¡ä»¶è·¯ç”±")
        print("4. æ‰“å¼€ Jupyter Notebook è¿›è¡Œäº¤äº’å¼å­¦ä¹ ")

        # è¯¢é—®æ˜¯å¦å¯åŠ¨Jupyter
        try:
            choice = input("\næ˜¯å¦å¯åŠ¨Jupyter Notebookè¿›è¡Œäº¤äº’å¼å­¦ä¹ ? (y/n): ").strip().lower()
            if choice in ['y', 'yes', 'æ˜¯', '']:
                self.start_jupyter()
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")

    def start_jupyter(self):
        """å¯åŠ¨Jupyter Notebook"""
        print("\nğŸš€ å¯åŠ¨Jupyter Notebook...")
        try:
            # å¯åŠ¨Jupyterå¹¶åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
            subprocess.Popen([
                sys.executable, "-m", "jupyter", "notebook",
                "--notebook-dir", str(self.project_root / "notebooks"),
                "--browser", "new"
            ])
            print("âœ… Jupyter Notebookå·²å¯åŠ¨")
        except Exception as e:
            print(f"âŒ å¯åŠ¨Jupyterå¤±è´¥: {e}")
            print("   ä½ å¯ä»¥æ‰‹åŠ¨è¿è¡Œ: jupyter notebook")

    def run(self, auto_start_examples: bool = False):
        """è¿è¡Œå¿«é€Ÿå¯åŠ¨æµç¨‹"""
        self.print_banner()

        print("ğŸ” æ­£åœ¨æ£€æŸ¥ä½ çš„ç¯å¢ƒ...")

        # 1. æ£€æŸ¥Pythonç‰ˆæœ¬
        if not self.check_python_version():
            print("\nâŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·å‡çº§Pythonåé‡è¯•")
            return False

        # 2. æ£€æŸ¥ä¾èµ–
        missing = self.check_dependencies()

        # 3. å®‰è£…ç¼ºå¤±ä¾èµ–
        if missing:
            if not self.install_dependencies(missing):
                print("\nâŒ ä¾èµ–å®‰è£…å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å®‰è£…åé‡è¯•")
                return False

        # 4. åˆ›å»ºç¯å¢ƒé…ç½®æ–‡ä»¶
        if not self.create_env_file():
            print("\nâŒ ç¯å¢ƒé…ç½®å¤±è´¥")
            return False

        # 5. è®¾ç½®é¡¹ç›®ç»“æ„
        if not self.setup_project_structure():
            print("\nâŒ é¡¹ç›®ç»“æ„è®¾ç½®å¤±è´¥")
            return False

        # 6. è¿è¡ŒåŸºç¡€æµ‹è¯•
        if not self.run_basic_test():
            print("\nâŒ åŸºç¡€æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®‰è£…")
            return False

        # 7. åˆ›å»ºç¤ºä¾‹æ–‡ä»¶
        if not self.create_examples():
            print("\nâŒ ç¤ºä¾‹æ–‡ä»¶åˆ›å»ºå¤±è´¥")
            return False

        print("\nğŸ‰ LangGraphç¯å¢ƒé…ç½®å®Œæˆï¼")
        print("\nğŸ“‚ é¡¹ç›®ç»“æ„:")
        print(f"   ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {self.project_root}")
        print(f"   ğŸ“ ç¤ºä¾‹ä»£ç : {self.project_root / 'examples'}")
        print(f"   ğŸ“ Jupyterç¬”è®°æœ¬: {self.project_root / 'notebooks'}")
        print(f"   ğŸ“„ ç¯å¢ƒé…ç½®: {self.project_root / '.env'}")

        # 8. è¯¢é—®æ˜¯å¦å¯åŠ¨äº¤äº’æ¨¡å¼
        self.start_interactive_mode()

        return True

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="LangGraphå¿«é€Ÿå¯åŠ¨å·¥å…·")
    parser.add_argument("--auto", action="store_true", help="è‡ªåŠ¨æ¨¡å¼ï¼Œä¸è¯¢é—®ç”¨æˆ·è¾“å…¥")
    parser.add_argument("--test-only", action="store_true", help="ä»…è¿è¡Œæµ‹è¯•")

    args = parser.parse_args()

    quick_start = QuickStart()

    if args.test_only:
        success = (
            quick_start.check_python_version() and
            len(quick_start.check_dependencies()) == 0 and
            quick_start.run_basic_test()
        )
        sys.exit(0 if success else 1)
    else:
        success = quick_start.run(auto_start_examples=args.auto)
        sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()