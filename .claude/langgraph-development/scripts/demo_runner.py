#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LangGraphæ¼”ç¤ºè¿è¡Œå™¨

å¿«é€Ÿè¿è¡Œå„ç§LangGraphæ¼”ç¤ºç¤ºä¾‹ï¼Œè®©åˆå­¦è€…ç«‹å³ä½“éªŒLangGraphçš„å¼ºå¤§åŠŸèƒ½
"""

import os
import sys
import time
import asyncio
from pathlib import Path
from typing import Dict, List, Any, Optional
import json

class DemoRunner:
    """LangGraphæ¼”ç¤ºè¿è¡Œå™¨"""

    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.demos = self._load_demos()

    def _load_demos(self) -> Dict:
        """åŠ è½½æ¼”ç¤ºé…ç½®"""
        return {
            "basic": {
                "title": "ğŸ¯ åŸºç¡€æ¼”ç¤º",
                "description": "å±•ç¤ºLangGraphçš„æ ¸å¿ƒæ¦‚å¿µ",
                "demos": [
                    {
                        "id": "hello_world",
                        "title": "Hello World",
                        "description": "æœ€ç®€å•çš„LangGraphåº”ç”¨",
                        "type": "builtin",
                        "function": "demo_hello_world"
                    },
                    {
                        "id": "state_flow",
                        "title": "çŠ¶æ€æµè½¬",
                        "description": "æ¼”ç¤ºçŠ¶æ€åœ¨å·¥ä½œæµä¸­çš„ä¼ é€’",
                        "type": "builtin",
                        "function": "demo_state_flow"
                    },
                    {
                        "id": "conditional_routing",
                        "title": "æ¡ä»¶è·¯ç”±",
                        "description": "æ ¹æ®æ¡ä»¶å†³å®šæ‰§è¡Œè·¯å¾„",
                        "type": "builtin",
                        "function": "demo_conditional_routing"
                    }
                ]
            },
            "advanced": {
                "title": "ğŸš€ é«˜çº§æ¼”ç¤º",
                "description": "å±•ç¤ºå¤æ‚çš„åº”ç”¨åœºæ™¯",
                "demos": [
                    {
                        "id": "memory_persistence",
                        "title": "æŒä¹…åŒ–å†…å­˜",
                        "description": "ä¿å­˜å’Œæ¢å¤å¯¹è¯çŠ¶æ€",
                        "type": "builtin",
                        "function": "demo_memory_persistence"
                    },
                    {
                        "id": "tool_integration",
                        "title": "å·¥å…·é›†æˆ",
                        "description": "é›†æˆå¤–éƒ¨å·¥å…·å’ŒAPI",
                        "type": "builtin",
                        "function": "demo_tool_integration"
                    },
                    {
                        "id": "error_handling",
                        "title": "é”™è¯¯å¤„ç†",
                        "description": "ä¼˜é›…åœ°å¤„ç†é”™è¯¯å’Œå¼‚å¸¸",
                        "type": "builtin",
                        "function": "demo_error_handling"
                    }
                ]
            }
        }

    def print_banner(self):
        """æ‰“å°æ¨ªå¹…"""
        banner = """
ğŸ¬ LangGraph æ¼”ç¤ºè¿è¡Œå™¨

ğŸ¯ ä½“éªŒLangGraphçš„å¼ºå¤§åŠŸèƒ½
ğŸš€ ä»ç®€å•åˆ°å¤æ‚çš„æ¼”ç¤ºç¤ºä¾‹
âš¡ å³æ—¶è¿è¡Œï¼Œæ— éœ€é…ç½®

        """
        print(banner)

    def display_menu(self) -> str:
        """æ˜¾ç¤ºä¸»èœå•"""
        print("è¯·é€‰æ‹©æ¼”ç¤ºç±»åˆ«:")
        print("0. ğŸ  ä¸»èœå•")
        print("1. ğŸ¯ åŸºç¡€æ¼”ç¤º")
        print("2. ğŸš€ é«˜çº§æ¼”ç¤º")
        print("3. ğŸ² éšæœºæ¼”ç¤º")
        print("q. ğŸšª é€€å‡º")
        return input("\nè¯·è¾“å…¥é€‰æ‹© (0-3, q): ").strip()

    def display_demo_menu(self, category: str) -> str:
        """æ˜¾ç¤ºæ¼”ç¤ºèœå•"""
        demos = self.demos[category]
        print(f"\n{demos['title']}")
        print("=" * len(demos['title']))
        print(f"{demos['description']}\n")

        for i, demo in enumerate(demos["demos"], 1):
            print(f"{i}. {demo['title']}")
            print(f"   {demo['description']}")

        print("\n0. ğŸ”™ è¿”å›ä¸»èœå•")
        return input(f"è¯·é€‰æ‹©æ¼”ç¤º (0-{len(demos['demos'])}): ").strip()

    async def run_demo(self, category: str, demo_index: int):
        """è¿è¡Œæ¼”ç¤º"""
        demos = self.demos[category]

        if demo_index < 0 or demo_index >= len(demos["demos"]):
            print("âŒ æ— æ•ˆçš„é€‰æ‹©")
            return

        demo = demos["demos"][demo_index]
        print(f"\nğŸ¬ æ¼”ç¤º: {demo['title']}")
        print("=" * 50)
        print(f"ğŸ“ {demo['description']}")
        print()

        try:
            # åŠ¨æ€è°ƒç”¨æ¼”ç¤ºå‡½æ•°
            demo_function = getattr(self, demo["function"])
            await demo_function()
        except AttributeError:
            print(f"âŒ æ¼”ç¤ºå‡½æ•°ä¸å­˜åœ¨: {demo['function']}")
        except Exception as e:
            print(f"âŒ æ¼”ç¤ºè¿è¡Œå¤±è´¥: {e}")

    async def demo_hello_world(self):
        """Hello Worldæ¼”ç¤º"""
        print("ğŸ¯ æ¼”ç¤º: åˆ›å»ºæœ€ç®€å•çš„LangGraphåº”ç”¨")

        # å¯¼å…¥å¿…è¦æ¨¡å—
        try:
            from langchain_core.messages import HumanMessage, AIMessage
            from langgraph.graph import StateGraph
            from typing import TypedDict, Annotated
            import operator
        except ImportError as e:
            print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
            print("è¯·ç¡®ä¿å·²å®‰è£…langgraphå’Œlangchain")
            return

        class State(TypedDict):
            messages: Annotated[list, operator.add]

        def simple_chatbot(state: State):
            """ç®€å•çš„èŠå¤©æœºå™¨äºº"""
            messages = state["messages"]
            last_message = messages[-1].content if messages else ""

            if "ä½ å¥½" in last_message:
                response = "ä½ å¥½ï¼æˆ‘æ˜¯LangGraphåŠ©æ‰‹!"
            elif "åŠŸèƒ½" in last_message:
                response = "LangGraphå¯ä»¥æ„å»ºå¤æ‚çš„AIå·¥ä½œæµ!"
            else:
                response = f"æ”¶åˆ°æ¶ˆæ¯: {last_message}"

            return {"messages": [AIMessage(content=response)]}

        # åˆ›å»ºå›¾
        print("\nğŸ“ åˆ›å»ºLangGraphå›¾...")
        graph = StateGraph(State)
        graph.add_node("chatbot", simple_chatbot)
        graph.set_entry_point("chatbot")
        graph.set_finish_point("chatbot")
        compiled_graph = graph.compile()

        print("âœ… å›¾åˆ›å»ºå®Œæˆ!")

        # è¿è¡Œæ¼”ç¤º
        print("\nğŸš€ è¿è¡Œæ¼”ç¤º...")
        test_inputs = [
            "ä½ å¥½ LangGraph!",
            "LangGraphæœ‰ä»€ä¹ˆåŠŸèƒ½?",
            "æ¼”ç¤ºç»“æŸ"
        ]

        for i, user_input in enumerate(test_inputs, 1):
            print(f"\n--- ç¤ºä¾‹ {i} ---")
            print(f"ç”¨æˆ·: {user_input}")

            result = await compiled_graph.ainvoke({
                "messages": [HumanMessage(content=user_input)]
            })

            ai_response = result["messages"][-1].content
            print(f"åŠ©æ‰‹: {ai_response}")

            # ç¨ä½œåœé¡¿ï¼Œä¾¿äºè§‚å¯Ÿ
            await asyncio.sleep(1)

        print("\nâœ… Hello Worldæ¼”ç¤ºå®Œæˆ!")

    async def demo_state_flow(self):
        """çŠ¶æ€æµè½¬æ¼”ç¤º"""
        print("ğŸ¯ æ¼”ç¤º: çŠ¶æ€åœ¨å·¥ä½œæµä¸­çš„ä¼ é€’")

        try:
            from langchain_core.messages import HumanMessage, AIMessage
            from langgraph.graph import StateGraph
            from typing import TypedDict, Annotated
            import operator
        except ImportError as e:
            print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
            return

        class ProcessState(TypedDict):
            input_text: str
            processed_text: str
            word_count: int
            step: str

        def text_analyzer(state: ProcessState):
            """æ–‡æœ¬åˆ†æå™¨"""
            text = state["input_text"]
            word_count = len(text.split())
            return {
                "processed_text": text.upper(),
                "word_count": word_count,
                "step": "analysis_completed"
            }

        def text_summarizer(state: ProcessState):
            """æ–‡æœ¬æ€»ç»“å™¨"""
            processed = state["processed_text"]
            summary = f"æ–‡æœ¬å·²å¤„ç†ï¼ŒåŒ…å«{state['word_count']}ä¸ªè¯"
            return {
                "processed_text": summary,
                "step": "summary_completed"
            }

        # åˆ›å»ºå¤šæ­¥éª¤å·¥ä½œæµ
        print("\nğŸ“ åˆ›å»ºå¤šæ­¥éª¤å·¥ä½œæµ...")
        graph = StateGraph(ProcessState)

        graph.add_node("analyzer", text_analyzer)
        graph.add_node("summarizer", text_summarizer)

        graph.set_entry_point("analyzer")
        graph.add_edge("analyzer", "summarizer")
        graph.set_finish_point("summarizer")

        compiled_graph = graph.compile()
        print("âœ… å¤šæ­¥éª¤å›¾åˆ›å»ºå®Œæˆ!")

        # è¿è¡Œæ¼”ç¤º
        print("\nğŸš€ è¿è¡ŒçŠ¶æ€æµè½¬æ¼”ç¤º...")
        test_text = "LangGraphæ˜¯ä¸€ä¸ªå¼ºå¤§çš„AIå·¥ä½œæµæ¡†æ¶"

        print(f"è¾“å…¥æ–‡æœ¬: {test_text}")

        result = await compiled_graph.ainvoke({
            "input_text": test_text,
            "processed_text": "",
            "word_count": 0,
            "step": "start"
        })

        print(f"\nå¤„ç†ç»“æœ:")
        print(f"åŸæ–‡æœ¬: {result['input_text']}")
        print(f"å¤„ç†å: {result['processed_text']}")
        print(f"è¯æ•°ç»Ÿè®¡: {result['word_count']}")
        print(f"å¤„ç†æ­¥éª¤: {result['step']}")

        print("\nâœ… çŠ¶æ€æµè½¬æ¼”ç¤ºå®Œæˆ!")

    async def demo_conditional_routing(self):
        """æ¡ä»¶è·¯ç”±æ¼”ç¤º"""
        print("ğŸ¯ æ¼”ç¤º: æ ¹æ®æ¡ä»¶å†³å®šæ‰§è¡Œè·¯å¾„")

        try:
            from langchain_core.messages import HumanMessage, AIMessage
            from langgraph.graph import StateGraph
            from typing import TypedDict, Annotated, Literal
            import operator
        except ImportError as e:
            print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
            return

        class RouterState(TypedDict):
            message: str
            category: str
            response: str

        def classifier(state: RouterState):
            """æ¶ˆæ¯åˆ†ç±»å™¨"""
            message = state["message"].lower()

            if any(word in message for word in ["è®¡ç®—", "ç®—", "æ•°å­¦"]):
                category = "math"
            elif any(word in message for word in ["ç¿»è¯‘", "english", "è‹±æ–‡"]):
                category = "translation"
            else:
                category = "general"

            return {"category": category}

        def math_handler(state: RouterState):
            """æ•°å­¦å¤„ç†å™¨"""
            return {"response": "æ­£åœ¨å¤„ç†æ•°å­¦è®¡ç®—..."}

        def translation_handler(state: RouterState):
            """ç¿»è¯‘å¤„ç†å™¨"""
            return {"response": "æ­£åœ¨å¤„ç†ç¿»è¯‘è¯·æ±‚..."}

        def general_handler(state: RouterState):
            """é€šç”¨å¤„ç†å™¨"""
            return {"response": "æ­£åœ¨å¤„ç†é€šç”¨è¯·æ±‚..."}

        def route_decision(state: RouterState) -> Literal["math", "translation", "general"]:
            """è·¯ç”±å†³ç­–å‡½æ•°"""
            return state["category"]

        # åˆ›å»ºæ¡ä»¶è·¯ç”±å›¾
        print("\nğŸ“ åˆ›å»ºæ¡ä»¶è·¯ç”±å›¾...")
        graph = StateGraph(RouterState)

        graph.add_node("classifier", classifier)
        graph.add_node("math_handler", math_handler)
        graph.add_node("translation_handler", translation_handler)
        graph.add_node("general_handler", general_handler)

        graph.set_entry_point("classifier")

        graph.add_conditional_edges(
            "classifier",
            route_decision,
            {
                "math": "math_handler",
                "translation": "translation_handler",
                "general": "general_handler"
            }
        )

        graph.set_finish_point("math_handler")
        graph.set_finish_point("translation_handler")
        graph.set_finish_point("general_handler")

        compiled_graph = graph.compile()
        print("âœ… æ¡ä»¶è·¯ç”±å›¾åˆ›å»ºå®Œæˆ!")

        # è¿è¡Œæ¼”ç¤º
        print("\nğŸš€ è¿è¡Œæ¡ä»¶è·¯ç”±æ¼”ç¤º...")
        test_messages = [
            "è®¡ç®— 123 + 456",
            "ç¿»è¯‘ hello world",
            "ä½ å¥½ï¼Œè¿™æ˜¯æ™®é€šæ¶ˆæ¯"
        ]

        for i, message in enumerate(test_messages, 1):
            print(f"\n--- ç¤ºä¾‹ {i} ---")
            print(f"æ¶ˆæ¯: {message}")

            result = await compiled_graph.ainvoke({
                "message": message,
                "category": "",
                "response": ""
            })

            print(f"åˆ†ç±»: {result['category']}")
            print(f"å“åº”: {result['response']}")
            await asyncio.sleep(1)

        print("\nâœ… æ¡ä»¶è·¯ç”±æ¼”ç¤ºå®Œæˆ!")

    async def demo_memory_persistence(self):
        """æŒä¹…åŒ–å†…å­˜æ¼”ç¤º"""
        print("ğŸ¯ æ¼”ç¤º: ä¿å­˜å’Œæ¢å¤å¯¹è¯çŠ¶æ€")

        try:
            from langchain_core.messages import HumanMessage, AIMessage
            from langgraph.graph import StateGraph
            from langgraph.checkpoint.memory import MemorySaver
            from typing import TypedDict, Annotated
            import operator
        except ImportError as e:
            print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
            return

        class ChatState(TypedDict):
            messages: Annotated[list, operator.add]
            conversation_count: int

        def memory_chatbot(state: ChatState):
            """æœ‰è®°å¿†çš„èŠå¤©æœºå™¨äºº"""
            messages = state["messages"]
            count = state.get("conversation_count", 0) + 1

            human_messages = [msg for msg in messages if isinstance(msg, HumanMessage)]
            if human_messages:
                last_message = human_messages[-1].content
                response = f"è¿™æ˜¯æˆ‘ä»¬çš„ç¬¬{count}æ¬¡å¯¹è¯ã€‚ä½ è¯´: {last_message}"
            else:
                response = "ä½ å¥½ï¼è®©æˆ‘ä»¬å¼€å§‹å¯¹è¯å§ã€‚"

            return {
                "messages": [AIMessage(content=response)],
                "conversation_count": count
            }

        # åˆ›å»ºå¸¦å†…å­˜çš„å›¾
        print("\nğŸ“ åˆ›å»ºå¸¦å†…å­˜çš„å·¥ä½œæµ...")
        graph = StateGraph(ChatState)
        graph.add_node("chatbot", memory_chatbot)
        graph.set_entry_point("chatbot")
        graph.set_finish_point("chatbot")

        # æ·»åŠ å†…å­˜æ£€æŸ¥ç‚¹
        memory = MemorySaver()
        compiled_graph = graph.compile(checkpointer=memory)
        print("âœ… å¸¦å†…å­˜çš„å·¥ä½œæµåˆ›å»ºå®Œæˆ!")

        # è¿è¡Œæ¼”ç¤º
        print("\nğŸš€ è¿è¡ŒæŒä¹…åŒ–å†…å­˜æ¼”ç¤º...")
        config = {"configurable": {"thread_id": "demo-conversation"}}

        # ç¬¬ä¸€è½®å¯¹è¯
        print("\n--- ç¬¬ä¸€è½®å¯¹è¯ ---")
        result1 = await compiled_graph.ainvoke(
            {"messages": [HumanMessage(content="ä½ å¥½")], "conversation_count": 0},
            config=config
        )
        print(f"ç”¨æˆ·: ä½ å¥½")
        print(f"åŠ©æ‰‹: {result1['messages'][-1].content}")

        # ç¬¬äºŒè½®å¯¹è¯
        print("\n--- ç¬¬äºŒè½®å¯¹è¯ ---")
        result2 = await compiled_graph.ainvoke(
            {"messages": [HumanMessage(content="å†è§")]},
            config=config
        )
        print(f"ç”¨æˆ·: å†è§")
        print(f"åŠ©æ‰‹: {result2['messages'][-1].content}")

        print("\nâœ… æŒä¹…åŒ–å†…å­˜æ¼”ç¤ºå®Œæˆ!")

    async def demo_tool_integration(self):
        """å·¥å…·é›†æˆæ¼”ç¤º"""
        print("ğŸ¯ æ¼”ç¤º: é›†æˆå¤–éƒ¨å·¥å…·å’ŒAPI")

        try:
            from langchain_core.messages import HumanMessage, AIMessage
            from langchain_core.tools import tool
            from langgraph.graph import StateGraph
            from langgraph.prebuilt import ToolNode
            from typing import TypedDict, Annotated
            import operator
            import time
        except ImportError as e:
            print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
            return

        # å®šä¹‰å·¥å…·
        @tool
        def get_current_time(query: str) -> str:
            """è·å–å½“å‰æ—¶é—´"""
            current_time = time.strftime("%Y-%m-%d %H:%M:%S")
            return f"å½“å‰æ—¶é—´æ˜¯: {current_time}"

        @tool
        def calculator(expression: str) -> str:
            """ç®€å•è®¡ç®—å™¨"""
            try:
                # å®‰å…¨çš„æ•°å­¦è¡¨è¾¾å¼è®¡ç®—
                safe_expression = expression.replace('^', '**')
                result = eval(safe_expression)
                return f"è®¡ç®—ç»“æœ: {result}"
            except:
                return "è®¡ç®—é”™è¯¯: æ— æ•ˆçš„æ•°å­¦è¡¨è¾¾å¼"

        class ToolState(TypedDict):
            messages: Annotated[list, operator.add]

        def should_use_tools(state: ToolState):
            """åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨å·¥å…·"""
            messages = state["messages"]
            last_message = messages[-1].content if messages else ""

            if any(keyword in last_message.lower() for keyword in ["æ—¶é—´", "å‡ ç‚¹", "time"]):
                return "tools"
            elif any(keyword in last_message.lower() for keyword in ["è®¡ç®—", "ç®—", "+", "-", "*", "/"]):
                return "tools"
            else:
                return "assistant"

        def assistant(state: ToolState):
            """åŠ©æ‰‹å“åº”"""
            messages = state["messages"]
            last_message = messages[-1].content if messages else ""
            return {"messages": [AIMessage(content=f"æˆ‘æ”¶åˆ°ä½ çš„æ¶ˆæ¯: {last_message}")]}

        # åˆ›å»ºå¸¦å·¥å…·çš„å›¾
        print("\nğŸ“ åˆ›å»ºå¸¦å·¥å…·çš„å·¥ä½œæµ...")
        tools = [get_current_time, calculator]
        tool_node = ToolNode(tools)

        graph = StateGraph(ToolState)
        graph.add_node("assistant", assistant)
        graph.add_node("tools", tool_node)

        graph.set_entry_point("assistant")
        graph.add_conditional_edges("assistant", should_use_tools)
        graph.add_edge("tools", "assistant")
        graph.set_finish_point("assistant")

        compiled_graph = graph.compile()
        print("âœ… å¸¦å·¥å…·çš„å·¥ä½œæµåˆ›å»ºå®Œæˆ!")

        # è¿è¡Œæ¼”ç¤º
        print("\nğŸš€ è¿è¡Œå·¥å…·é›†æˆæ¼”ç¤º...")
        test_queries = [
            "ç°åœ¨å‡ ç‚¹äº†?",
            "è®¡ç®— 25 * 4",
            "ä½ å¥½ï¼Œè¿™æ˜¯æ™®é€šæ¶ˆæ¯"
        ]

        for i, query in enumerate(test_queries, 1):
            print(f"\n--- ç¤ºä¾‹ {i} ---")
            print(f"ç”¨æˆ·: {query}")

            result = await compiled_graph.ainvoke({
                "messages": [HumanMessage(content=query)]
            })

            ai_response = result["messages"][-1].content
            print(f"åŠ©æ‰‹: {ai_response}")
            await asyncio.sleep(1)

        print("\nâœ… å·¥å…·é›†æˆæ¼”ç¤ºå®Œæˆ!")

    async def demo_error_handling(self):
        """é”™è¯¯å¤„ç†æ¼”ç¤º"""
        print("ğŸ¯ æ¼”ç¤º: ä¼˜é›…åœ°å¤„ç†é”™è¯¯å’Œå¼‚å¸¸")

        try:
            from langchain_core.messages import HumanMessage, AIMessage
            from langgraph.graph import StateGraph, END
            from typing import TypedDict, Annotated, Literal
            import operator
        except ImportError as e:
            print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
            return

        class ErrorState(TypedDict):
            messages: Annotated[list, operator.add]
            error_count: int
            processing_successful: bool

        def safe_processor(state: ErrorState):
            """å®‰å…¨çš„å¤„ç†å™¨ï¼ˆå¯èƒ½å¤±è´¥ï¼‰"""
            messages = state["messages"]
            last_message = messages[-1].content if messages else ""

            error_count = state.get("error_count", 0)

            # æ¨¡æ‹Ÿå¤„ç†å¤±è´¥çš„æƒ…å†µ
            if "é”™è¯¯" in last_message and error_count < 2:
                return {
                    "error_count": error_count + 1,
                    "processing_successful": False,
                    "messages": [AIMessage(content="å¤„ç†å¤±è´¥ï¼Œæ­£åœ¨é‡è¯•...")]
                }
            elif "é”™è¯¯" in last_message and error_count >= 2:
                return {
                    "error_count": error_count,
                    "processing_successful": False,
                    "messages": [AIMessage(content="å¤šæ¬¡é‡è¯•å¤±è´¥ï¼Œæ”¾å¼ƒå¤„ç†")]
                }
            else:
                return {
                    "error_count": 0,
                    "processing_successful": True,
                    "messages": [AIMessage(content=f"æˆåŠŸå¤„ç†: {last_message}")]
                }

        def retry_logic(state: ErrorState) -> Literal["retry", "end"]:
            """é‡è¯•é€»è¾‘"""
            if state.get("processing_successful", False):
                return "end"
            elif state.get("error_count", 0) < 2:
                return "retry"
            else:
                return "end"

        # åˆ›å»ºå¸¦é”™è¯¯å¤„ç†çš„å›¾
        print("\nğŸ“ åˆ›å»ºå¸¦é”™è¯¯å¤„ç†çš„å·¥ä½œæµ...")
        graph = StateGraph(ErrorState)
        graph.add_node("processor", safe_processor)

        graph.set_entry_point("processor")
        graph.add_conditional_edges("processor", retry_logic)
        graph.add_edge("processor", "processor")  # é‡è¯•è¾¹
        graph.set_finish_point("processor")

        compiled_graph = graph.compile()
        print("âœ… å¸¦é”™è¯¯å¤„ç†çš„å·¥ä½œæµåˆ›å»ºå®Œæˆ!")

        # è¿è¡Œæ¼”ç¤º
        print("\nğŸš€ è¿è¡Œé”™è¯¯å¤„ç†æ¼”ç¤º...")
        test_inputs = [
            "æ­£å¸¸å¤„ç†",
            "é”™è¯¯å¤„ç†",
            "å†æ¬¡é”™è¯¯å¤„ç†"
        ]

        for i, user_input in enumerate(test_inputs, 1):
            print(f"\n--- ç¤ºä¾‹ {i} ---")
            print(f"è¾“å…¥: {user_input}")

            result = await compiled_graph.ainvoke({
                "messages": [HumanMessage(content=user_input)],
                "error_count": 0,
                "processing_successful": False
            })

            ai_response = result["messages"][-1].content
            print(f"å¤„ç†æ¬¡æ•°: {result.get('error_count', 0) + 1}")
            print(f"å“åº”: {ai_response}")
            await asyncio.sleep(1)

        print("\nâœ… é”™è¯¯å¤„ç†æ¼”ç¤ºå®Œæˆ!")

    def run_random_demo(self):
        """è¿è¡Œéšæœºæ¼”ç¤º"""
        import random

        all_demos = []
        for category, category_data in self.demos.items():
            for demo in category_data["demos"]:
                all_demos.append((category, demo))

        if all_demos:
            category, demo = random.choice(all_demos)
            print(f"\nğŸ² éšæœºé€‰æ‹©: {demo['title']} ({category})")
            return asyncio.run(self.run_demo(category, category_data["demos"].index(demo)))

    async def run(self):
        """è¿è¡Œæ¼”ç¤ºè¿è¡Œå™¨"""
        self.print_banner()

        while True:
            try:
                choice = self.display_menu()

                if choice == "q":
                    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨LangGraphæ¼”ç¤ºè¿è¡Œå™¨!")
                    break
                elif choice == "0":
                    pass  # æ˜¾ç¤ºä¸»èœå•
                elif choice == "1":
                    demo_choice = self.display_demo_menu("basic")
                    if demo_choice != "0":
                        await self.run_demo("basic", int(demo_choice) - 1)
                elif choice == "2":
                    demo_choice = self.display_demo_menu("advanced")
                    if demo_choice != "0":
                        await self.run_demo("advanced", int(demo_choice) - 1)
                elif choice == "3":
                    self.run_random_demo()
                else:
                    print("âŒ æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡è¯•")

                if choice != "q":
                    input("\næŒ‰å›è½¦é”®ç»§ç»­...")

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å†è§!")
                break
            except Exception as e:
                print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
                input("æŒ‰å›è½¦é”®ç»§ç»­...")

def main():
    """ä¸»å‡½æ•°"""
    runner = DemoRunner()
    asyncio.run(runner.run())

if __name__ == "__main__":
    main()